---
title: "Week 02 exercise"
author: "Lukasz K Bonenberg"
output:
  html_document:
    highlight: pygments
    theme: cerulean
    #toc: yes
---

```{r, echo=FALSE,warning = FALSE}
setwd("d:/tmp/Dropbox/Edu/other/BigDataMeasuringandPredictingHumanBehaviour/")
rm(list=ls(all=TRUE))

library(knitr)
opts_chunk$set(echo = T, cache = T, cache.path = "cache/", fig.path = "figure/", warning = FALSE,error=FALSE,message=F,strip.white=T)
#http://yihui.name/knitr/options/
```


#<a name="intro">Introdcution</a> 

In this project we will try and visualise what people are looking for at Wikipedia using < http://stats.grok.se/> website. 


# downlad data

```{r}
#install.packages("RCurl")  # Install the JSON parser
library(RCurl)
library(RJSONIO)  # Load the JSON parser



targetURL<-"http://stats.grok.se/json/en/201601/Friday"
rawData <- getURL(targetURL)
parsedData <- fromJSON(rawData)

```

## understand data

Curently dates are treated as our row names. Lets create data frame and sort out dates and data order.

```{r}
names(parsedData$daily_views)

parseData <- data.frame(Date=names(parsedData$daily_views),  # get the names
        Views=parsedData$daily_views,  # get the data points
        row.names=NULL) # stop using the dates as names
parseData$Date < -as.Date(parseData$Date)
parseData <- parseData[order(parseData$Date),]
row.names(parseData) <- NULL #reset row numbers

```

## Visualise data

```{r}
library(ggplot2)
library(gtable)

plot(parsedData$daily_views)
plot_data <- qplot(x=Date,y=Views,data=parseData,group=1)
plot_data +geom_line()+theme_bw()+theme(axis.text.x = element_text(angle = 90, hjust = 1))

```


# Automating the process

Let's now lookinto automating this process. Overall principle is quite easy, yust acccess relevant website address: stats.grok.se/json/en/yyyymm/KEYword 

```{r}
#month <- 1
#year <- 2016
keyword<-"smoke"
```

We want to list all data 2008-October 2014

```{r}

baseUrl <- "stats.grok.se/json/en/"
listUrl <- NULL #init

for (year in (2008:2014)){
  for (month in 1:12){
    if ((year == 2014) && (month>10)){
      next #skip run
    }
    date <- sprintf("%04i%02i",year,month)
    getUrl<- paste0(baseUrl,date,'/',keyword)
    
    #print(getUrl)
    listUrl <- c(listUrl,getUrl)
  
  }#month in 1:12){
}#year in (2008:2015){}


print(listUrl)
```

Now we want to downlad it

```{r}
allViewsData <- NULL
for (theURL in listUrl) {
    
        cat("Downloading data from", theURL, "\n") 
        
        rawData <- getURL(theURL)
        parsedData <- fromJSON(rawData)
        viewsData <- data.frame(Date=names(parsedData$daily_views),
            Views=parsedData$daily_views,row.names=NULL)
                    
        allViewsData<-rbind(allViewsData,viewsData)
}

allViewsData$Date<-as.Date(allViewsData$Date) #convert to date
allViewsData<- allViewsData[order(allViewsData$Date),]
allViewsData<-subset(allViewsData,!is.na(Date))#remove nans


```

And visualise it


```{r}
library(ggplot2)
library(gtable)

#plot(allViewsData$daily_views)
plot_data <- qplot(x=Date,y=Views,data=allViewsData,group=1)
plot_data +geom_line()+theme_bw()+theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

